{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Machine_Learning_Accelerator_NLP_11_Recurrent_Neural_Networks.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBSAruYo4Abm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fd5ed55b-3fc0-4672-f432-d4f9f81eb458"
      },
      "source": [
        "! pip install -q gluonnlp mxnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348kB 2.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 55.0MB 74kB/s \n",
            "\u001b[?25h  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QzcBT6A3pid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, autograd\n",
        "from mxnet.gluon import nn, rnn, Trainer\n",
        "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52OXXt7c4bBo",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "544bfc45-9655-4597-ddfb-24662507027c"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d32d93e-2c2f-4d98-ac92-b0910a4698e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d32d93e-2c2f-4d98-ac92-b0910a4698e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving AMAZON-REVIEW-DATA-CLASSIFICATION.csv to AMAZON-REVIEW-DATA-CLASSIFICATION.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SSmZl0X3pin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['AMAZON-REVIEW-DATA-CLASSIFICATION.csv']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWn7YB-Q3piv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ffc700f-3878-4f84-a84b-2a34a6caff52"
      },
      "source": [
        "df[\"isPositive\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    43692\n",
              "0.0    26308\n",
              "Name: isPositive, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QX1j_K-3pi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1e5acb33-a154-423a-d50f-da3d552d9d4b"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70000 entries, 0 to 69999\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   reviewText  69989 non-null  object \n",
            " 1   summary     69986 non-null  object \n",
            " 2   verified    70000 non-null  bool   \n",
            " 3   time        70000 non-null  int64  \n",
            " 4   log_votes   70000 non-null  float64\n",
            " 5   isPositive  70000 non-null  float64\n",
            "dtypes: bool(1), float64(2), int64(1), object(2)\n",
            "memory usage: 2.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shVKvCLj3pi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "08cb5d5c-88d0-4272-caa8-e0e1e5793590"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>log_votes</th>\n",
              "      <th>isPositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.000000e+04</td>\n",
              "      <td>70000.000000</td>\n",
              "      <td>70000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.370112e+09</td>\n",
              "      <td>0.535257</td>\n",
              "      <td>0.624171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.149986e+08</td>\n",
              "      <td>0.962677</td>\n",
              "      <td>0.484340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.421920e+08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.322870e+09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.406160e+09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.448669e+09</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.538438e+09</td>\n",
              "      <td>7.110696</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               time     log_votes    isPositive\n",
              "count  7.000000e+04  70000.000000  70000.000000\n",
              "mean   1.370112e+09      0.535257      0.624171\n",
              "std    1.149986e+08      0.962677      0.484340\n",
              "min    9.421920e+08      0.000000      0.000000\n",
              "25%    1.322870e+09      0.000000      0.000000\n",
              "50%    1.406160e+09      0.000000      1.000000\n",
              "75%    1.448669e+09      1.098612      1.000000\n",
              "max    1.538438e+09      7.110696      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnQBN0TX3pjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9bf76a4c-0d56-4094-e3e5-dbc55cb482e7"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reviewText    11\n",
              "summary       14\n",
              "verified       0\n",
              "time           0\n",
              "log_votes      0\n",
              "isPositive     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZozmHaM3pjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text, val_text, train_label, val_label = \\\n",
        "    train_test_split(df[\"reviewText\"].tolist(),\n",
        "                     df[\"isPositive\"].tolist(),\n",
        "                     test_size=0.10,\n",
        "                     shuffle=True,\n",
        "                     random_state=360)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY8I57hu3pjJ",
        "colab_type": "text"
      },
      "source": [
        "</br>\n",
        "Text cleaning: Simple text cleaning operations. We won't do stemming or lemmatization as our word vectors already cover different forms of words. We are using GloVe word embeddings for 6 billion words, phrases or punctuations in this example.\n",
        "</br>\n",
        "Tokenization: Tokenizing all sentences\n",
        "</br>\n",
        "Creating vocabulary: We will create a vocabulary of the tokens. In this vocabulary, tokens will map to unique ids, such as \"car\"->32, \"house\"->651, etc.\n",
        "</br>\n",
        "Transforming text: Tokenized sentences will be mapped to unique ids. For example: [\"this\", \"is\", \"sentence\"] -> [13, 54, 412].\n",
        "</br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhXPmv43pjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac881287-2068-40a3-cd86-9ab44ba008a8"
      },
      "source": [
        "import nltk, gluonnlp\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def cleanStr(text):\n",
        "    \n",
        "    # Check if the sentence is a missing value\n",
        "    if isinstance(text, str) == False:\n",
        "        text = \"\"\n",
        "            \n",
        "    # Remove leading/trailing whitespace\n",
        "    text = text.lower().strip()\n",
        "    # Remove extra space and tabs\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    # Remove HTML tags/markups\n",
        "    text = re.compile('<.*?>').sub('', text)\n",
        "    return text\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = []\n",
        "    text = cleanStr(text)\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        tokens.append(word)\n",
        "    return tokens\n",
        "\n",
        "def createVocabulary(text_list, min_freq):\n",
        "    all_tokens = []\n",
        "    for sentence in text_list:\n",
        "        all_tokens += tokenize(sentence)\n",
        "    # Calculate token frequencies\n",
        "    counter = gluonnlp.data.count_tokens(all_tokens)\n",
        "    # Create the vocabulary\n",
        "    vocab = gluonnlp.Vocab(counter,\n",
        "                           min_freq = min_freq,\n",
        "                           unknown_token = '<unk>',\n",
        "                           padding_token = None,\n",
        "                           bos_token = None,\n",
        "                           eos_token = None)\n",
        "    \n",
        "    return vocab\n",
        "\n",
        "def transformText(text, vocab, max_length):\n",
        "    token_arr = np.zeros((max_length,))\n",
        "    tokens = tokenize(text)[0:max_length]\n",
        "    for idx, token in enumerate(tokens):\n",
        "        try:\n",
        "            # Use the vocabulary index of the token\n",
        "            token_arr[idx] = vocab.token_to_idx[token]\n",
        "        except:\n",
        "            token_arr[idx] = 0 # Unknown word\n",
        "    return token_arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TTKAHeV3pjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "df947e04-1d53-4e04-d18a-8da8c7e504ff"
      },
      "source": [
        "min_freq = 5\n",
        "max_length = 250\n",
        "\n",
        "print(\"Creating the vocabulary\")\n",
        "vocab = createVocabulary(train_text, min_freq)\n",
        "print(\"Transforming training texts\")\n",
        "train_text_transformed = nd.array([transformText(text, vocab, max_length) for text in train_text])\n",
        "print(\"Transforming validation texts\")\n",
        "val_text_transformed = nd.array([transformText(text, vocab, max_length) for text in val_text])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the vocabulary\n",
            "Transforming training texts\n",
            "Transforming validation texts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xtO0QmV3pjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "36af6254-1b7f-46ca-b4bc-d3bb914c447d"
      },
      "source": [
        "print(\"Vocabulary index for computer:\", vocab['computer'])\n",
        "print(\"Vocabulary index for beautiful:\", vocab['beautiful'])\n",
        "print(\"Vocabulary index for code:\", vocab['code'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary index for computer: 67\n",
            "Vocabulary index for beautiful: 1976\n",
            "Vocabulary index for code: 402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL-tSqOT3pjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4cc7c2b9-5be0-4cfd-9d61-137a3b5afee1"
      },
      "source": [
        "from mxnet.contrib import text\n",
        "glove = text.embedding.create('glove',\n",
        "                              pretrained_file_name = 'glove.6B.50d.txt')\n",
        "embedding_matrix = glove.get_vecs_by_tokens(vocab.idx_to_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/embeddings/glove/glove.6B.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/embeddings/glove/glove.6B.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAp68lKv3pjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of the state vectors\n",
        "hidden_size = 12\n",
        "\n",
        "# General NN training parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "# Embedding vector and vocabulary sizes\n",
        "num_embed = 50 # glove.6B.50d.txt\n",
        "vocab_size = len(vocab.token_to_idx.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tP1-b4W3pje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet.gluon.data import ArrayDataset, DataLoader\n",
        "\n",
        "train_label = nd.array(train_label)\n",
        "val_label = nd.array(val_label)\n",
        "\n",
        "train_dataset = ArrayDataset(train_text_transformed, train_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4tmnMdl3pjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = mx.cpu() # use mx.gpu() if you are using GPU\n",
        "\n",
        "model = nn.Sequential()\n",
        "model.add(nn.Embedding(vocab_size, num_embed), # Embedding layer\n",
        "          rnn.RNN(hidden_size, num_layers=1),  # Recurrent layer\n",
        "          nn.Dense(1, activation='sigmoid'))   # Output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TL06Nmj3pjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize networks parameters\n",
        "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
        "\n",
        "# We set the embedding layer's parameters from GloVe\n",
        "model[0].weight.set_data(embedding_matrix.as_in_context(context))\n",
        "# We won't change/train the embedding layer\n",
        "model[0].collect_params().setattr('grad_req', 'null')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6fHtcui3pjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting our trainer\n",
        "trainer = Trainer(model.collect_params(),\n",
        "                        'sgd',\n",
        "                        {'learning_rate': learning_rate})\n",
        "\n",
        "# We will use Binary Cross-entropy loss\n",
        "cross_ent_loss = SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KZdW17b3pjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6609c039-6389-4af8-9c3a-0830f7ceb20b"
      },
      "source": [
        "import time\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    training_loss = 0\n",
        "    # Training loop, train the network\n",
        "    for idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data = data.as_in_context(context)\n",
        "        target = target.as_in_context(context)\n",
        "        \n",
        "        with autograd.record():\n",
        "            output = model(data)\n",
        "            L = cross_ent_loss(output, target)\n",
        "            training_loss += nd.sum(L).asscalar()\n",
        "            L.backward()\n",
        "        trainer.step(data.shape[0])\n",
        "    \n",
        "    # Calculate validation loss\n",
        "    val_predictions = model(val_text_transformed.as_in_context(context))\n",
        "    val_loss = nd.sum(cross_ent_loss(val_predictions, val_label)).asscalar()\n",
        "    \n",
        "    # Let's take the average losses\n",
        "    training_loss = training_loss / len(train_label)\n",
        "    val_loss = val_loss / len(val_label)\n",
        "    \n",
        "    end = time.time()\n",
        "    print(\"Epoch %s. Train_loss %f Validation_loss %f Seconds %f\" % \\\n",
        "          (epoch, training_loss, val_loss, end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Train_loss 0.599052 Validation_loss 0.558403 Seconds 16.874201\n",
            "Epoch 1. Train_loss 0.529220 Validation_loss 0.525489 Seconds 16.610989\n",
            "Epoch 2. Train_loss 0.499743 Validation_loss 0.507534 Seconds 16.351708\n",
            "Epoch 3. Train_loss 0.480511 Validation_loss 0.496742 Seconds 16.496183\n",
            "Epoch 4. Train_loss 0.465536 Validation_loss 0.486157 Seconds 16.189243\n",
            "Epoch 5. Train_loss 0.453515 Validation_loss 0.477877 Seconds 16.542446\n",
            "Epoch 6. Train_loss 0.443975 Validation_loss 0.472121 Seconds 16.392223\n",
            "Epoch 7. Train_loss 0.436183 Validation_loss 0.466666 Seconds 16.401354\n",
            "Epoch 8. Train_loss 0.429550 Validation_loss 0.462500 Seconds 16.372777\n",
            "Epoch 9. Train_loss 0.423831 Validation_loss 0.458332 Seconds 16.542792\n",
            "Epoch 10. Train_loss 0.418815 Validation_loss 0.454241 Seconds 19.967718\n",
            "Epoch 11. Train_loss 0.414449 Validation_loss 0.452654 Seconds 16.646130\n",
            "Epoch 12. Train_loss 0.410677 Validation_loss 0.449388 Seconds 16.677658\n",
            "Epoch 13. Train_loss 0.407193 Validation_loss 0.447839 Seconds 16.430948\n",
            "Epoch 14. Train_loss 0.403983 Validation_loss 0.447011 Seconds 16.185060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE8M4EmU3pjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e893b709-6194-4fd1-f9ca-0a13c073e812"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Get validation predictions\n",
        "val_predictions = model(val_text_transformed.as_in_context(context))\n",
        "\n",
        "val_label = nd.array(val_label)\n",
        "\n",
        "# Round predictions: 1 if pred>0.5, 0 otherwise\n",
        "val_predictions = np.round(val_predictions.asnumpy())\n",
        "\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(val_label.asnumpy(), val_predictions))\n",
        "print(\"Accuracy\")\n",
        "print(accuracy_score(val_label.asnumpy(), val_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.78      0.75      2627\n",
            "         1.0       0.86      0.82      0.84      4373\n",
            "\n",
            "    accuracy                           0.80      7000\n",
            "   macro avg       0.79      0.80      0.79      7000\n",
            "weighted avg       0.81      0.80      0.80      7000\n",
            "\n",
            "Accuracy\n",
            "0.803\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}